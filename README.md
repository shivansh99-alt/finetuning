# Finetuning
This repository contains a reproducible pipeline to fine-tune causal language models (GPT-style) on domain-specific datasets. It includes data formats, preprocessing scripts, example training commands (LoRA/PEFT and full fine-tuning), and safety/privacy guidance for medical data. 
